{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import wrappers\n",
    "from lib import dqn_model\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "DEFAULT_ENV_NAME = \"PongNoFrameskip-v4\"\n",
    "MEAN_REWARD_BOUND = 19.5\n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 64\n",
    "REPLAY_SIZE = 10000\n",
    "REPLAY_START_SIZE = 10000\n",
    "LEARNING_RATE = 1e-4\n",
    "SYNC_TARGET_FRAMES = 1000\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_FINAL = 0.02\n",
    "EPSILON_DECAY_LAST_FRAME = 10**5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experience = collections.namedtuple('Experience', field_names=['state', 'action', 'reward', 'done', 'new_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperienceBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = collections.deque(maxlen=capacity)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    def append(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, replace=False)\n",
    "        states, actions, rewards, dones, next_states = zip(*[self.buffer[idx] for idx in indices])\n",
    "        return np.array(states), np.array(actions), np.array(rewards, dtype=np.float32), np.array(dones, dtype=np.uint8), np.array(next_states)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, env, exp_buffer):\n",
    "        self.env = env\n",
    "        self.exp_buffer = exp_buffer\n",
    "        self._reset()\n",
    "        \n",
    "    def _reset(self):\n",
    "        self.state = env.reset()\n",
    "        self.total_reward = 0.0\n",
    "        \n",
    "    def play_step(self, net, epsilon=0.0, device=\"cpu\"):\n",
    "        done_reward = None\n",
    "        \n",
    "        if np.random.random() < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            state_a = np.array([self.state], copy=False)\n",
    "            state_v = torch.tensor(state_a).to(device)\n",
    "            q_vals_v = net(state_v)\n",
    "            _, act_v = torch.max(q_vals_v, dim=1)\n",
    "            action = int(act_v.item())\n",
    "        new_state, reward, is_done, _ = self.env.step(action)\n",
    "        self.total_reward += reward\n",
    "        new_state = new_state\n",
    "        exp = Experience(self.state, action, reward, is_done, new_state)\n",
    "        self.exp_buffer.append(exp)\n",
    "        self.state = new_state\n",
    "        if is_done:\n",
    "            done_reward = self.total_reward\n",
    "            self._reset()\n",
    "        return done_reward\n",
    "    \n",
    "def calc_loss(batch, net, tgt_net, device=\"cpu\"):\n",
    "    states, actions, rewards, dones, next_states = batch\n",
    "    states_v = torch.tensor(states).to(device)\n",
    "    next_states_v = torch.tensor(next_states).to(device)\n",
    "    actions_v = torch.tensor(actions).to(device)\n",
    "    rewards_v = torch.tensor(rewards).to(device)\n",
    "    done_mask = torch.ByteTensor(dones).to(device)\n",
    "    state_action_values = net(states_v).gather(1,actions_v.unsqueeze(-1)).squeeze(-1)\n",
    "    next_state_values = tgt_net(next_states_v).max(1)[0]\n",
    "    next_state_values[done_mask] = 0.0\n",
    "    next_state_values = next_state_values.detach()\n",
    "    expected_state_action_values = next_state_values * GAMMA + rewards_v\n",
    "    return nn.MSELoss()(state_action_values, expected_state_action_values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=3136, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=6, bias=True)\n",
      "  )\n",
      ")\n",
      "\u001b[33mWARN: <class 'lib.wrappers.MaxAndSkipEnv'> doesn't implement 'reset' method, but it implements deprecated '_reset' method.\u001b[0m\n",
      "1156: done 1 games, mean reward -20.000, eps 0.99, speed 137.96 f/s\n",
      "2112: done 2 games, mean reward -20.000, eps 0.98, speed 168.12 f/s\n",
      "3257: done 3 games, mean reward -19.667, eps 0.97, speed 169.18 f/s\n",
      "4376: done 4 games, mean reward -19.250, eps 0.96, speed 171.64 f/s\n",
      "5380: done 5 games, mean reward -19.600, eps 0.95, speed 169.48 f/s\n",
      "6276: done 6 games, mean reward -19.667, eps 0.94, speed 172.38 f/s\n",
      "7195: done 7 games, mean reward -19.571, eps 0.93, speed 169.99 f/s\n",
      "8017: done 8 games, mean reward -19.750, eps 0.92, speed 167.40 f/s\n",
      "9057: done 9 games, mean reward -19.778, eps 0.91, speed 165.05 f/s\n",
      "9937: done 10 games, mean reward -19.900, eps 0.90, speed 168.72 f/s\n",
      "10837: done 11 games, mean reward -19.909, eps 0.89, speed 26.68 f/s\n",
      "11627: done 12 games, mean reward -20.000, eps 0.88, speed 24.66 f/s\n",
      "12512: done 13 games, mean reward -20.000, eps 0.87, speed 26.78 f/s\n",
      "13302: done 14 games, mean reward -20.071, eps 0.87, speed 26.28 f/s\n",
      "14064: done 15 games, mean reward -20.133, eps 0.86, speed 26.37 f/s\n",
      "14873: done 16 games, mean reward -20.188, eps 0.85, speed 27.47 f/s\n",
      "16141: done 17 games, mean reward -20.000, eps 0.84, speed 26.37 f/s\n",
      "16991: done 18 games, mean reward -20.056, eps 0.83, speed 26.63 f/s\n",
      "17951: done 19 games, mean reward -20.105, eps 0.82, speed 27.27 f/s\n",
      "18742: done 20 games, mean reward -20.150, eps 0.81, speed 26.62 f/s\n",
      "19663: done 21 games, mean reward -20.143, eps 0.80, speed 26.53 f/s\n",
      "20453: done 22 games, mean reward -20.182, eps 0.80, speed 26.91 f/s\n",
      "21243: done 23 games, mean reward -20.217, eps 0.79, speed 26.30 f/s\n",
      "22095: done 24 games, mean reward -20.250, eps 0.78, speed 26.72 f/s\n",
      "23044: done 25 games, mean reward -20.240, eps 0.77, speed 27.31 f/s\n",
      "23864: done 26 games, mean reward -20.269, eps 0.76, speed 26.60 f/s\n",
      "24705: done 27 games, mean reward -20.259, eps 0.75, speed 27.00 f/s\n",
      "25556: done 28 games, mean reward -20.286, eps 0.74, speed 26.67 f/s\n",
      "26337: done 29 games, mean reward -20.310, eps 0.74, speed 27.24 f/s\n",
      "27129: done 30 games, mean reward -20.333, eps 0.73, speed 24.52 f/s\n",
      "28000: done 31 games, mean reward -20.355, eps 0.72, speed 27.32 f/s\n",
      "29062: done 32 games, mean reward -20.375, eps 0.71, speed 28.06 f/s\n",
      "30062: done 33 games, mean reward -20.394, eps 0.70, speed 28.26 f/s\n",
      "31183: done 34 games, mean reward -20.353, eps 0.69, speed 28.16 f/s\n",
      "32246: done 35 games, mean reward -20.343, eps 0.68, speed 28.11 f/s\n",
      "33386: done 36 games, mean reward -20.278, eps 0.67, speed 26.43 f/s\n",
      "34336: done 37 games, mean reward -20.297, eps 0.66, speed 26.61 f/s\n",
      "35492: done 38 games, mean reward -20.263, eps 0.65, speed 26.36 f/s\n",
      "36665: done 39 games, mean reward -20.205, eps 0.63, speed 26.65 f/s\n",
      "37747: done 40 games, mean reward -20.200, eps 0.62, speed 26.46 f/s\n",
      "38839: done 41 games, mean reward -20.195, eps 0.61, speed 26.70 f/s\n",
      "39996: done 42 games, mean reward -20.190, eps 0.60, speed 26.57 f/s\n",
      "41277: done 43 games, mean reward -20.163, eps 0.59, speed 26.61 f/s\n",
      "42417: done 44 games, mean reward -20.182, eps 0.58, speed 26.66 f/s\n",
      "43459: done 45 games, mean reward -20.200, eps 0.57, speed 26.32 f/s\n",
      "44600: done 46 games, mean reward -20.174, eps 0.55, speed 26.51 f/s\n",
      "46052: done 47 games, mean reward -20.106, eps 0.54, speed 26.43 f/s\n",
      "47326: done 48 games, mean reward -20.083, eps 0.53, speed 26.51 f/s\n",
      "48669: done 49 games, mean reward -20.041, eps 0.51, speed 26.47 f/s\n",
      "50387: done 50 games, mean reward -19.960, eps 0.50, speed 26.45 f/s\n",
      "51621: done 51 games, mean reward -19.980, eps 0.48, speed 26.43 f/s\n",
      "53057: done 52 games, mean reward -19.962, eps 0.47, speed 26.34 f/s\n",
      "54361: done 53 games, mean reward -19.962, eps 0.46, speed 26.29 f/s\n",
      "55975: done 54 games, mean reward -19.926, eps 0.44, speed 26.18 f/s\n",
      "57628: done 55 games, mean reward -19.873, eps 0.42, speed 26.54 f/s\n",
      "59222: done 56 games, mean reward -19.839, eps 0.41, speed 26.45 f/s\n",
      "60729: done 57 games, mean reward -19.825, eps 0.39, speed 26.45 f/s\n",
      "62263: done 58 games, mean reward -19.810, eps 0.38, speed 26.03 f/s\n",
      "63865: done 59 games, mean reward -19.780, eps 0.36, speed 26.32 f/s\n",
      "65477: done 60 games, mean reward -19.750, eps 0.35, speed 26.31 f/s\n",
      "67705: done 61 games, mean reward -19.656, eps 0.32, speed 26.35 f/s\n",
      "69229: done 62 games, mean reward -19.661, eps 0.31, speed 26.18 f/s\n",
      "70895: done 63 games, mean reward -19.667, eps 0.29, speed 24.03 f/s\n",
      "72812: done 64 games, mean reward -19.625, eps 0.27, speed 25.51 f/s\n",
      "74876: done 65 games, mean reward -19.569, eps 0.25, speed 26.24 f/s\n",
      "76546: done 66 games, mean reward -19.561, eps 0.23, speed 26.16 f/s\n",
      "78017: done 67 games, mean reward -19.552, eps 0.22, speed 26.18 f/s\n",
      "80095: done 68 games, mean reward -19.515, eps 0.20, speed 26.12 f/s\n",
      "81921: done 69 games, mean reward -19.493, eps 0.18, speed 26.05 f/s\n",
      "83840: done 70 games, mean reward -19.500, eps 0.16, speed 26.13 f/s\n",
      "85965: done 71 games, mean reward -19.423, eps 0.14, speed 26.00 f/s\n",
      "87836: done 72 games, mean reward -19.417, eps 0.12, speed 26.09 f/s\n",
      "90436: done 73 games, mean reward -19.356, eps 0.10, speed 26.06 f/s\n",
      "92791: done 74 games, mean reward -19.257, eps 0.07, speed 25.97 f/s\n",
      "95054: done 75 games, mean reward -19.253, eps 0.05, speed 25.98 f/s\n",
      "97824: done 76 games, mean reward -19.171, eps 0.02, speed 25.97 f/s\n",
      "99989: done 77 games, mean reward -19.143, eps 0.02, speed 25.88 f/s\n",
      "102130: done 78 games, mean reward -19.154, eps 0.02, speed 25.94 f/s\n",
      "104916: done 79 games, mean reward -19.063, eps 0.02, speed 25.94 f/s\n",
      "107360: done 80 games, mean reward -19.012, eps 0.02, speed 25.87 f/s\n",
      "110405: done 81 games, mean reward -18.926, eps 0.02, speed 25.69 f/s\n",
      "112523: done 82 games, mean reward -18.902, eps 0.02, speed 25.89 f/s\n",
      "115246: done 83 games, mean reward -18.843, eps 0.02, speed 25.90 f/s\n",
      "117905: done 84 games, mean reward -18.798, eps 0.02, speed 25.91 f/s\n",
      "120247: done 85 games, mean reward -18.741, eps 0.02, speed 25.94 f/s\n",
      "121903: done 86 games, mean reward -18.733, eps 0.02, speed 25.86 f/s\n",
      "124655: done 87 games, mean reward -18.701, eps 0.02, speed 25.88 f/s\n",
      "126997: done 88 games, mean reward -18.670, eps 0.02, speed 25.94 f/s\n",
      "129280: done 89 games, mean reward -18.640, eps 0.02, speed 25.92 f/s\n",
      "132266: done 90 games, mean reward -18.611, eps 0.02, speed 25.86 f/s\n",
      "135326: done 91 games, mean reward -18.505, eps 0.02, speed 25.91 f/s\n",
      "137789: done 92 games, mean reward -18.424, eps 0.02, speed 25.89 f/s\n",
      "140500: done 93 games, mean reward -18.376, eps 0.02, speed 25.88 f/s\n",
      "142951: done 94 games, mean reward -18.319, eps 0.02, speed 25.92 f/s\n",
      "145987: done 95 games, mean reward -18.200, eps 0.02, speed 25.91 f/s\n",
      "149461: done 96 games, mean reward -17.979, eps 0.02, speed 25.88 f/s\n",
      "152160: done 97 games, mean reward -17.897, eps 0.02, speed 25.93 f/s\n",
      "155539: done 98 games, mean reward -17.755, eps 0.02, speed 25.72 f/s\n",
      "159100: done 99 games, mean reward -17.636, eps 0.02, speed 25.92 f/s\n",
      "162668: done 100 games, mean reward -17.470, eps 0.02, speed 25.90 f/s\n",
      "167142: done 101 games, mean reward -17.300, eps 0.02, speed 25.67 f/s\n",
      "170561: done 102 games, mean reward -17.160, eps 0.02, speed 25.88 f/s\n",
      "174222: done 103 games, mean reward -17.030, eps 0.02, speed 25.90 f/s\n",
      "177851: done 104 games, mean reward -16.910, eps 0.02, speed 25.87 f/s\n",
      "181238: done 105 games, mean reward -16.670, eps 0.02, speed 25.94 f/s\n",
      "184123: done 106 games, mean reward -16.370, eps 0.02, speed 25.87 f/s\n",
      "187764: done 107 games, mean reward -16.130, eps 0.02, speed 25.86 f/s\n",
      "190520: done 108 games, mean reward -15.820, eps 0.02, speed 25.91 f/s\n",
      "192702: done 109 games, mean reward -15.470, eps 0.02, speed 25.90 f/s\n",
      "194900: done 110 games, mean reward -15.110, eps 0.02, speed 25.86 f/s\n",
      "196967: done 111 games, mean reward -14.750, eps 0.02, speed 25.92 f/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199439: done 112 games, mean reward -14.410, eps 0.02, speed 25.89 f/s\n",
      "202389: done 113 games, mean reward -14.150, eps 0.02, speed 25.70 f/s\n",
      "205116: done 114 games, mean reward -13.840, eps 0.02, speed 25.93 f/s\n",
      "207747: done 115 games, mean reward -13.550, eps 0.02, speed 25.86 f/s\n",
      "209513: done 116 games, mean reward -13.140, eps 0.02, speed 25.84 f/s\n",
      "211886: done 117 games, mean reward -12.860, eps 0.02, speed 25.89 f/s\n",
      "214929: done 118 games, mean reward -12.630, eps 0.02, speed 25.91 f/s\n",
      "217375: done 119 games, mean reward -12.310, eps 0.02, speed 25.87 f/s\n",
      "219276: done 120 games, mean reward -11.930, eps 0.02, speed 25.90 f/s\n",
      "221570: done 121 games, mean reward -11.600, eps 0.02, speed 25.93 f/s\n",
      "223589: done 122 games, mean reward -11.210, eps 0.02, speed 25.93 f/s\n",
      "226147: done 123 games, mean reward -10.920, eps 0.02, speed 25.87 f/s\n",
      "228098: done 124 games, mean reward -10.540, eps 0.02, speed 25.87 f/s\n",
      "231078: done 125 games, mean reward -10.320, eps 0.02, speed 25.88 f/s\n",
      "234132: done 126 games, mean reward -10.050, eps 0.02, speed 25.86 f/s\n",
      "236837: done 127 games, mean reward -9.740, eps 0.02, speed 25.91 f/s\n",
      "239025: done 128 games, mean reward -9.350, eps 0.02, speed 25.92 f/s\n",
      "241469: done 129 games, mean reward -8.990, eps 0.02, speed 25.87 f/s\n",
      "243540: done 130 games, mean reward -8.620, eps 0.02, speed 25.89 f/s\n",
      "245650: done 131 games, mean reward -8.250, eps 0.02, speed 25.90 f/s\n",
      "248383: done 132 games, mean reward -7.970, eps 0.02, speed 25.72 f/s\n",
      "250205: done 133 games, mean reward -7.570, eps 0.02, speed 25.86 f/s\n",
      "252385: done 134 games, mean reward -7.230, eps 0.02, speed 25.90 f/s\n",
      "254272: done 135 games, mean reward -6.840, eps 0.02, speed 25.75 f/s\n",
      "256631: done 136 games, mean reward -6.520, eps 0.02, speed 25.66 f/s\n",
      "258695: done 137 games, mean reward -6.140, eps 0.02, speed 25.74 f/s\n",
      "260614: done 138 games, mean reward -5.770, eps 0.02, speed 25.74 f/s\n",
      "262544: done 139 games, mean reward -5.400, eps 0.02, speed 25.69 f/s\n",
      "264589: done 140 games, mean reward -5.030, eps 0.02, speed 25.73 f/s\n",
      "266803: done 141 games, mean reward -4.680, eps 0.02, speed 25.85 f/s\n",
      "269119: done 142 games, mean reward -4.360, eps 0.02, speed 25.83 f/s\n",
      "270992: done 143 games, mean reward -4.000, eps 0.02, speed 25.77 f/s\n",
      "273402: done 144 games, mean reward -3.650, eps 0.02, speed 25.83 f/s\n",
      "275976: done 145 games, mean reward -3.320, eps 0.02, speed 25.84 f/s\n",
      "277701: done 146 games, mean reward -2.940, eps 0.02, speed 25.76 f/s\n",
      "279751: done 147 games, mean reward -2.610, eps 0.02, speed 25.78 f/s\n",
      "281621: done 148 games, mean reward -2.220, eps 0.02, speed 25.85 f/s\n",
      "284090: done 149 games, mean reward -1.910, eps 0.02, speed 25.82 f/s\n",
      "286136: done 150 games, mean reward -1.580, eps 0.02, speed 25.78 f/s\n",
      "287803: done 151 games, mean reward -1.170, eps 0.02, speed 25.85 f/s\n",
      "290197: done 152 games, mean reward -0.870, eps 0.02, speed 25.81 f/s\n",
      "291988: done 153 games, mean reward -0.480, eps 0.02, speed 25.81 f/s\n",
      "294071: done 154 games, mean reward -0.130, eps 0.02, speed 25.76 f/s\n",
      "295858: done 155 games, mean reward 0.230, eps 0.02, speed 25.51 f/s\n",
      "298358: done 156 games, mean reward 0.520, eps 0.02, speed 25.83 f/s\n",
      "300327: done 157 games, mean reward 0.900, eps 0.02, speed 25.87 f/s\n",
      "302165: done 158 games, mean reward 1.290, eps 0.02, speed 25.72 f/s\n",
      "304558: done 159 games, mean reward 1.600, eps 0.02, speed 25.84 f/s\n",
      "306764: done 160 games, mean reward 1.890, eps 0.02, speed 25.85 f/s\n",
      "308866: done 161 games, mean reward 2.200, eps 0.02, speed 25.77 f/s\n",
      "310817: done 162 games, mean reward 2.560, eps 0.02, speed 25.73 f/s\n",
      "312543: done 163 games, mean reward 2.960, eps 0.02, speed 25.83 f/s\n",
      "314207: done 164 games, mean reward 3.330, eps 0.02, speed 25.75 f/s\n",
      "316104: done 165 games, mean reward 3.670, eps 0.02, speed 25.82 f/s\n",
      "318134: done 166 games, mean reward 4.030, eps 0.02, speed 25.75 f/s\n",
      "319875: done 167 games, mean reward 4.410, eps 0.02, speed 25.81 f/s\n",
      "321688: done 168 games, mean reward 4.770, eps 0.02, speed 25.85 f/s\n",
      "323719: done 169 games, mean reward 5.110, eps 0.02, speed 25.79 f/s\n",
      "325462: done 170 games, mean reward 5.510, eps 0.02, speed 25.80 f/s\n",
      "327127: done 171 games, mean reward 5.850, eps 0.02, speed 25.83 f/s\n",
      "328917: done 172 games, mean reward 6.220, eps 0.02, speed 25.88 f/s\n",
      "331133: done 173 games, mean reward 6.490, eps 0.02, speed 25.83 f/s\n",
      "332799: done 174 games, mean reward 6.810, eps 0.02, speed 25.76 f/s\n",
      "334944: done 175 games, mean reward 7.130, eps 0.02, speed 25.86 f/s\n",
      "336831: done 176 games, mean reward 7.440, eps 0.02, speed 25.80 f/s\n",
      "339092: done 177 games, mean reward 7.750, eps 0.02, speed 25.81 f/s\n",
      "341018: done 178 games, mean reward 8.150, eps 0.02, speed 25.49 f/s\n",
      "342839: done 179 games, mean reward 8.470, eps 0.02, speed 25.78 f/s\n",
      "344833: done 180 games, mean reward 8.800, eps 0.02, speed 25.79 f/s\n",
      "346813: done 181 games, mean reward 9.090, eps 0.02, speed 25.89 f/s\n",
      "349174: done 182 games, mean reward 9.380, eps 0.02, speed 25.79 f/s\n",
      "350951: done 183 games, mean reward 9.710, eps 0.02, speed 25.83 f/s\n",
      "352926: done 184 games, mean reward 10.050, eps 0.02, speed 25.86 f/s\n",
      "354620: done 185 games, mean reward 10.400, eps 0.02, speed 25.75 f/s\n",
      "356696: done 186 games, mean reward 10.730, eps 0.02, speed 25.80 f/s\n",
      "358640: done 187 games, mean reward 11.060, eps 0.02, speed 25.81 f/s\n",
      "360399: done 188 games, mean reward 11.410, eps 0.02, speed 25.77 f/s\n",
      "362442: done 189 games, mean reward 11.740, eps 0.02, speed 25.83 f/s\n",
      "364536: done 190 games, mean reward 12.050, eps 0.02, speed 25.75 f/s\n",
      "366735: done 191 games, mean reward 12.290, eps 0.02, speed 25.83 f/s\n",
      "368864: done 192 games, mean reward 12.560, eps 0.02, speed 25.85 f/s\n",
      "371034: done 193 games, mean reward 12.860, eps 0.02, speed 25.78 f/s\n",
      "372848: done 194 games, mean reward 13.180, eps 0.02, speed 25.76 f/s\n",
      "374673: done 195 games, mean reward 13.440, eps 0.02, speed 25.86 f/s\n",
      "376900: done 196 games, mean reward 13.540, eps 0.02, speed 25.81 f/s\n",
      "379044: done 197 games, mean reward 13.800, eps 0.02, speed 25.76 f/s\n",
      "380710: done 198 games, mean reward 14.040, eps 0.02, speed 25.82 f/s\n",
      "382747: done 199 games, mean reward 14.250, eps 0.02, speed 25.79 f/s\n",
      "384791: done 200 games, mean reward 14.440, eps 0.02, speed 25.83 f/s\n",
      "386860: done 201 games, mean reward 14.620, eps 0.02, speed 25.76 f/s\n",
      "389477: done 202 games, mean reward 14.790, eps 0.02, speed 25.60 f/s\n",
      "391379: done 203 games, mean reward 15.030, eps 0.02, speed 25.80 f/s\n",
      "393461: done 204 games, mean reward 15.270, eps 0.02, speed 25.73 f/s\n",
      "395595: done 205 games, mean reward 15.410, eps 0.02, speed 25.72 f/s\n",
      "397475: done 206 games, mean reward 15.480, eps 0.02, speed 25.78 f/s\n",
      "399417: done 207 games, mean reward 15.630, eps 0.02, speed 25.83 f/s\n",
      "401987: done 208 games, mean reward 15.600, eps 0.02, speed 25.81 f/s\n",
      "403923: done 209 games, mean reward 15.610, eps 0.02, speed 25.78 f/s\n",
      "405684: done 210 games, mean reward 15.640, eps 0.02, speed 25.84 f/s\n",
      "407348: done 211 games, mean reward 15.680, eps 0.02, speed 25.78 f/s\n",
      "409370: done 212 games, mean reward 15.690, eps 0.02, speed 25.81 f/s\n",
      "411302: done 213 games, mean reward 15.810, eps 0.02, speed 25.66 f/s\n",
      "413962: done 214 games, mean reward 15.790, eps 0.02, speed 25.81 f/s\n",
      "416028: done 215 games, mean reward 15.880, eps 0.02, speed 25.76 f/s\n",
      "418002: done 216 games, mean reward 15.850, eps 0.02, speed 25.77 f/s\n",
      "419934: done 217 games, mean reward 15.920, eps 0.02, speed 25.77 f/s\n",
      "421872: done 218 games, mean reward 16.090, eps 0.02, speed 25.84 f/s\n",
      "424343: done 219 games, mean reward 16.090, eps 0.02, speed 25.84 f/s\n",
      "426567: done 220 games, mean reward 16.060, eps 0.02, speed 25.75 f/s\n",
      "428450: done 221 games, mean reward 16.130, eps 0.02, speed 25.76 f/s\n",
      "430597: done 222 games, mean reward 16.070, eps 0.02, speed 25.83 f/s\n",
      "432613: done 223 games, mean reward 16.150, eps 0.02, speed 25.75 f/s\n",
      "434741: done 224 games, mean reward 16.110, eps 0.02, speed 25.53 f/s\n",
      "436902: done 225 games, mean reward 16.250, eps 0.02, speed 25.84 f/s\n",
      "438992: done 226 games, mean reward 16.350, eps 0.02, speed 25.81 f/s\n",
      "440892: done 227 games, mean reward 16.410, eps 0.02, speed 25.77 f/s\n",
      "443111: done 228 games, mean reward 16.390, eps 0.02, speed 25.84 f/s\n",
      "445215: done 229 games, mean reward 16.410, eps 0.02, speed 25.78 f/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447054: done 230 games, mean reward 16.430, eps 0.02, speed 25.77 f/s\n",
      "448837: done 231 games, mean reward 16.470, eps 0.02, speed 25.72 f/s\n",
      "450773: done 232 games, mean reward 16.570, eps 0.02, speed 25.75 f/s\n",
      "452556: done 233 games, mean reward 16.570, eps 0.02, speed 25.79 f/s\n",
      "454618: done 234 games, mean reward 16.570, eps 0.02, speed 25.76 f/s\n",
      "456836: done 235 games, mean reward 16.520, eps 0.02, speed 25.73 f/s\n",
      "458906: done 236 games, mean reward 16.530, eps 0.02, speed 25.82 f/s\n",
      "461633: done 237 games, mean reward 16.440, eps 0.02, speed 25.79 f/s\n",
      "463330: done 238 games, mean reward 16.470, eps 0.02, speed 25.74 f/s\n",
      "465075: done 239 games, mean reward 16.470, eps 0.02, speed 25.78 f/s\n",
      "467155: done 240 games, mean reward 16.480, eps 0.02, speed 25.81 f/s\n",
      "468913: done 241 games, mean reward 16.520, eps 0.02, speed 25.77 f/s\n",
      "471275: done 242 games, mean reward 16.470, eps 0.02, speed 25.83 f/s\n",
      "473000: done 243 games, mean reward 16.500, eps 0.02, speed 25.74 f/s\n",
      "475166: done 244 games, mean reward 16.470, eps 0.02, speed 25.79 f/s\n",
      "477003: done 245 games, mean reward 16.530, eps 0.02, speed 25.83 f/s\n",
      "478702: done 246 games, mean reward 16.550, eps 0.02, speed 25.71 f/s\n",
      "480458: done 247 games, mean reward 16.600, eps 0.02, speed 25.72 f/s\n",
      "482204: done 248 games, mean reward 16.590, eps 0.02, speed 25.45 f/s\n",
      "483869: done 249 games, mean reward 16.660, eps 0.02, speed 25.76 f/s\n",
      "485874: done 250 games, mean reward 16.660, eps 0.02, speed 25.82 f/s\n",
      "487756: done 251 games, mean reward 16.640, eps 0.02, speed 25.73 f/s\n",
      "489607: done 252 games, mean reward 16.730, eps 0.02, speed 25.83 f/s\n",
      "491285: done 253 games, mean reward 16.740, eps 0.02, speed 25.76 f/s\n",
      "493147: done 254 games, mean reward 16.760, eps 0.02, speed 25.81 f/s\n",
      "494871: done 255 games, mean reward 16.770, eps 0.02, speed 25.75 f/s\n",
      "496624: done 256 games, mean reward 16.860, eps 0.02, speed 25.76 f/s\n",
      "498835: done 257 games, mean reward 16.770, eps 0.02, speed 25.85 f/s\n",
      "500735: done 258 games, mean reward 16.750, eps 0.02, speed 25.80 f/s\n",
      "502702: done 259 games, mean reward 16.790, eps 0.02, speed 25.72 f/s\n",
      "504488: done 260 games, mean reward 16.880, eps 0.02, speed 25.84 f/s\n",
      "506267: done 261 games, mean reward 16.900, eps 0.02, speed 25.75 f/s\n",
      "507985: done 262 games, mean reward 16.930, eps 0.02, speed 25.77 f/s\n",
      "509830: done 263 games, mean reward 16.930, eps 0.02, speed 25.74 f/s\n",
      "511733: done 264 games, mean reward 16.900, eps 0.02, speed 25.71 f/s\n",
      "513426: done 265 games, mean reward 16.920, eps 0.02, speed 25.80 f/s\n",
      "515090: done 266 games, mean reward 16.950, eps 0.02, speed 25.74 f/s\n",
      "516924: done 267 games, mean reward 16.940, eps 0.02, speed 25.81 f/s\n",
      "518842: done 268 games, mean reward 16.930, eps 0.02, speed 25.76 f/s\n",
      "520536: done 269 games, mean reward 16.970, eps 0.02, speed 25.85 f/s\n",
      "522898: done 270 games, mean reward 16.830, eps 0.02, speed 25.81 f/s\n",
      "524647: done 271 games, mean reward 16.830, eps 0.02, speed 25.76 f/s\n",
      "526496: done 272 games, mean reward 16.810, eps 0.02, speed 25.70 f/s\n",
      "528548: done 273 games, mean reward 16.840, eps 0.02, speed 25.46 f/s\n",
      "530330: done 274 games, mean reward 16.820, eps 0.02, speed 25.64 f/s\n",
      "532954: done 275 games, mean reward 16.800, eps 0.02, speed 25.72 f/s\n",
      "534774: done 276 games, mean reward 16.800, eps 0.02, speed 25.62 f/s\n",
      "536660: done 277 games, mean reward 16.850, eps 0.02, speed 25.71 f/s\n",
      "538789: done 278 games, mean reward 16.790, eps 0.02, speed 25.73 f/s\n",
      "540473: done 279 games, mean reward 16.790, eps 0.02, speed 25.63 f/s\n",
      "542174: done 280 games, mean reward 16.800, eps 0.02, speed 25.67 f/s\n",
      "543839: done 281 games, mean reward 16.830, eps 0.02, speed 25.69 f/s\n",
      "546031: done 282 games, mean reward 16.850, eps 0.02, speed 25.69 f/s\n",
      "547943: done 283 games, mean reward 16.800, eps 0.02, speed 25.72 f/s\n",
      "549761: done 284 games, mean reward 16.810, eps 0.02, speed 25.63 f/s\n",
      "551614: done 285 games, mean reward 16.770, eps 0.02, speed 25.75 f/s\n",
      "553605: done 286 games, mean reward 16.790, eps 0.02, speed 25.69 f/s\n",
      "556030: done 287 games, mean reward 16.760, eps 0.02, speed 25.70 f/s\n",
      "557978: done 288 games, mean reward 16.750, eps 0.02, speed 25.69 f/s\n",
      "560054: done 289 games, mean reward 16.750, eps 0.02, speed 25.74 f/s\n",
      "561907: done 290 games, mean reward 16.790, eps 0.02, speed 25.72 f/s\n",
      "563771: done 291 games, mean reward 16.830, eps 0.02, speed 25.72 f/s\n",
      "565490: done 292 games, mean reward 16.860, eps 0.02, speed 25.63 f/s\n",
      "567366: done 293 games, mean reward 16.890, eps 0.02, speed 25.67 f/s\n",
      "569312: done 294 games, mean reward 16.880, eps 0.02, speed 25.77 f/s\n",
      "570978: done 295 games, mean reward 16.890, eps 0.02, speed 25.62 f/s\n",
      "573023: done 296 games, mean reward 16.940, eps 0.02, speed 25.68 f/s\n",
      "574845: done 297 games, mean reward 16.970, eps 0.02, speed 25.41 f/s\n",
      "576632: done 298 games, mean reward 16.970, eps 0.02, speed 25.67 f/s\n",
      "578520: done 299 games, mean reward 17.010, eps 0.02, speed 25.72 f/s\n",
      "580470: done 300 games, mean reward 17.010, eps 0.02, speed 25.63 f/s\n",
      "582534: done 301 games, mean reward 17.030, eps 0.02, speed 25.71 f/s\n",
      "584566: done 302 games, mean reward 17.080, eps 0.02, speed 25.73 f/s\n",
      "586345: done 303 games, mean reward 17.100, eps 0.02, speed 25.65 f/s\n",
      "588105: done 304 games, mean reward 17.110, eps 0.02, speed 25.71 f/s\n",
      "589963: done 305 games, mean reward 17.120, eps 0.02, speed 25.70 f/s\n",
      "592252: done 306 games, mean reward 17.050, eps 0.02, speed 25.72 f/s\n",
      "594123: done 307 games, mean reward 17.030, eps 0.02, speed 25.73 f/s\n",
      "595887: done 308 games, mean reward 17.150, eps 0.02, speed 25.62 f/s\n",
      "597643: done 309 games, mean reward 17.180, eps 0.02, speed 25.71 f/s\n",
      "599387: done 310 games, mean reward 17.200, eps 0.02, speed 25.67 f/s\n",
      "601135: done 311 games, mean reward 17.200, eps 0.02, speed 25.69 f/s\n",
      "602847: done 312 games, mean reward 17.270, eps 0.02, speed 25.71 f/s\n",
      "604750: done 313 games, mean reward 17.250, eps 0.02, speed 25.67 f/s\n",
      "606951: done 314 games, mean reward 17.340, eps 0.02, speed 25.75 f/s\n",
      "608824: done 315 games, mean reward 17.360, eps 0.02, speed 25.71 f/s\n",
      "611176: done 316 games, mean reward 17.310, eps 0.02, speed 25.66 f/s\n",
      "613022: done 317 games, mean reward 17.330, eps 0.02, speed 25.74 f/s\n",
      "614686: done 318 games, mean reward 17.340, eps 0.02, speed 25.70 f/s\n",
      "616492: done 319 games, mean reward 17.420, eps 0.02, speed 25.70 f/s\n",
      "618397: done 320 games, mean reward 17.470, eps 0.02, speed 25.66 f/s\n",
      "620156: done 321 games, mean reward 17.450, eps 0.02, speed 25.69 f/s\n",
      "622453: done 322 games, mean reward 17.470, eps 0.02, speed 25.54 f/s\n",
      "624377: done 323 games, mean reward 17.460, eps 0.02, speed 25.69 f/s\n",
      "626438: done 324 games, mean reward 17.470, eps 0.02, speed 25.66 f/s\n",
      "628197: done 325 games, mean reward 17.500, eps 0.02, speed 25.74 f/s\n",
      "630079: done 326 games, mean reward 17.510, eps 0.02, speed 25.68 f/s\n",
      "632043: done 327 games, mean reward 17.510, eps 0.02, speed 25.72 f/s\n",
      "634052: done 328 games, mean reward 17.520, eps 0.02, speed 25.70 f/s\n",
      "636308: done 329 games, mean reward 17.480, eps 0.02, speed 25.72 f/s\n",
      "638094: done 330 games, mean reward 17.500, eps 0.02, speed 25.68 f/s\n",
      "640044: done 331 games, mean reward 17.460, eps 0.02, speed 25.71 f/s\n",
      "641891: done 332 games, mean reward 17.460, eps 0.02, speed 25.66 f/s\n",
      "643737: done 333 games, mean reward 17.460, eps 0.02, speed 25.71 f/s\n",
      "645644: done 334 games, mean reward 17.480, eps 0.02, speed 25.71 f/s\n",
      "647520: done 335 games, mean reward 17.520, eps 0.02, speed 25.69 f/s\n",
      "649539: done 336 games, mean reward 17.540, eps 0.02, speed 25.68 f/s\n",
      "651577: done 337 games, mean reward 17.630, eps 0.02, speed 25.68 f/s\n",
      "653455: done 338 games, mean reward 17.610, eps 0.02, speed 26.38 f/s\n",
      "655241: done 339 games, mean reward 17.620, eps 0.02, speed 26.97 f/s\n",
      "657318: done 340 games, mean reward 17.590, eps 0.02, speed 26.90 f/s\n",
      "659086: done 341 games, mean reward 17.600, eps 0.02, speed 27.00 f/s\n",
      "661227: done 342 games, mean reward 17.690, eps 0.02, speed 26.81 f/s\n",
      "663394: done 343 games, mean reward 17.650, eps 0.02, speed 26.93 f/s\n",
      "665274: done 344 games, mean reward 17.720, eps 0.02, speed 26.88 f/s\n",
      "667348: done 345 games, mean reward 17.720, eps 0.02, speed 26.92 f/s\n",
      "669671: done 346 games, mean reward 17.590, eps 0.02, speed 25.58 f/s\n",
      "671460: done 347 games, mean reward 17.570, eps 0.02, speed 25.78 f/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673126: done 348 games, mean reward 17.580, eps 0.02, speed 25.66 f/s\n",
      "674791: done 349 games, mean reward 17.580, eps 0.02, speed 19.40 f/s\n",
      "676896: done 350 games, mean reward 17.560, eps 0.02, speed 21.34 f/s\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\")\n",
    "    env = wrappers.make_env(DEFAULT_ENV_NAME)\n",
    "    net = dqn_model.DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
    "    tgt_net = dqn_model.DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
    "    writer = SummaryWriter(comment=\"-\"+DEFAULT_ENV_NAME)\n",
    "    print(net)\n",
    "    buffer = ExperienceBuffer(REPLAY_SIZE)\n",
    "    agent = Agent(env, buffer)\n",
    "    epsilon = EPSILON_START\n",
    "    optimizer= optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "    total_rewards = []\n",
    "    frame_idx = 0\n",
    "    ts_frame = 0\n",
    "    ts = time.time()\n",
    "    best_mean_reward = None\n",
    "    while True:\n",
    "        env.render()\n",
    "        frame_idx += 1\n",
    "        epsilon = max(EPSILON_FINAL, EPSILON_START- frame_idx / EPSILON_DECAY_LAST_FRAME)\n",
    "        reward = agent.play_step(net, epsilon, device=device)\n",
    "        if reward is not None:\n",
    "            total_rewards.append(reward)\n",
    "            speed = (frame_idx - ts_frame) / (time.time() - ts)\n",
    "            ts_frame = frame_idx\n",
    "            ts = time.time()\n",
    "            mean_reward = np.mean(total_rewards[-100:])\n",
    "            print(\"%d: done %d games, mean reward %.3f, eps %.2f, speed %.2f f/s\"%(frame_idx, len(total_rewards), mean_reward,epsilon,speed))\n",
    "            writer.add_scalar(\"epsilon\",epsilon,frame_idx)\n",
    "            writer.add_scalar(\"speed\",speed,frame_idx)\n",
    "            writer.add_scalar(\"reward_100\", mean_reward,frame_idx)\n",
    "            writer.add_scalar(\"reward\",reward,frame_idx)\n",
    "            if best_mean_reward is None or best_mean_reward < mean_reward:\n",
    "                torch.save(net.state_dict(), DEFAULT_ENV_NAME + \"best.dat\")\n",
    "                if best_mean_reward is not None:\n",
    "                    print(\"Best mean reward updated %.3f -> %.3f, model saved\"%(best_mean_reward,mean_reward))\n",
    "                    best_mean_reward = mean_reward\n",
    "            if mean_reward > MEAN_REWARD_BOUND:\n",
    "                print(\"Solved in %d frames!\"% frame_idx)\n",
    "                break\n",
    "        if len(buffer) < REPLAY_START_SIZE:\n",
    "            continue\n",
    "        if frame_idx % SYNC_TARGET_FRAMES == 0:\n",
    "            tgt_net.load_state_dict(net.state_dict())\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        batch = buffer.sample(BATCH_SIZE)\n",
    "        loss_t = calc_loss(batch, net, tgt_net, device=device)\n",
    "        loss_t.backward()\n",
    "        optimizer.step()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
